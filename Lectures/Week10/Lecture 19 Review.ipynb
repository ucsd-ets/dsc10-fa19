{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: the usual imports\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "\n",
    "cm = ConfigManager()\n",
    "cm.update(\n",
    "   \"livereveal\", {\n",
    "       'width': 1200,\n",
    "       'height': 700,\n",
    "       \"scroll\": True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements\n",
    "\n",
    "* CAPE evaluations\n",
    "* Final exam is in two days\n",
    "    - Saturday 8-11am\n",
    "    - seating chart on Piazza\n",
    "    - bring student ID, pen or pencil, no calculators\n",
    "    - reference sheet provided\n",
    "* Studying\n",
    "    - DSC Study Jam tonight 5:30-10pm\n",
    "    - Practice finals on Piazza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "restaurants = Table.read_table('restaurants.csv')\n",
    "restaurants.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = restaurants.select('business_name', 'inspection_date', 'inspection_score', 'risk_category', 'Neighborhoods', 'Zip Codes')\n",
    "restaurants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risk = restaurants.where('inspection_score', are.above(-1)).where('risk_category', are.not_equal_to('nan'))\n",
    "at_risk.hist('inspection_score')#, group='risk_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare high risk restaurants to low risk restaurants and see if their inspection scores are different. What technique should we use?\n",
    "\n",
    "A. A/B testing  \n",
    "B. Standard hypothesis testing  \n",
    "C. Bootstrapping  \n",
    "D. Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you state the null and alternative hypotheses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "high_low = at_risk.where('risk_category', are.contained_in(['High Risk', 'Low Risk']))\n",
    "high_low = high_low.select('inspection_score', 'risk_category')\n",
    "high_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low.sample(with_replacement = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_labels = high_low.sample(with_replacement = False).column(1)\n",
    "original_and_shuffled = high_low.with_column('Shuffled Label', shuffled_labels)\n",
    "original_and_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_and_shuffled.hist('inspection_score', group='risk_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_and_shuffled.hist('inspection_score', group='Shuffled Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the two groups in the first histogram (A and B) are susbstantially more different than the two groups in the second histogram (C and D). What test statistic(s) can we use to quantify the difference between the two groups displayed in a given histogram?\n",
    "\n",
    "A. total variation distance  \n",
    "B. difference in the means  \n",
    "C. either of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_and_shuffled.group('risk_category', np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_and_shuffled.group('Shuffled Label', np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed_means = original_and_shuffled.group('risk_category', np.mean).column('inspection_score mean')\n",
    "observed_difference = observed_means.item(1) - observed_means.item(0)\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_means = original_and_shuffled.group('Shuffled Label', np.mean).column('inspection_score mean')\n",
    "simulated_difference = simulated_means.item(1) - simulated_means.item(0)\n",
    "simulated_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_statistic():\n",
    "    shuffled_labels = high_low.sample(with_replacement = False).column(1)\n",
    "    original_and_shuffled = high_low.with_column('Shuffled Label', shuffled_labels)\n",
    "    simulated_means = original_and_shuffled.group('Shuffled Label', np.mean).column('inspection_score mean')\n",
    "    simulated_difference = simulated_means.item(1) - simulated_means.item(0)\n",
    "    return simulated_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_test_statistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_stats = make_array()\n",
    "\n",
    "for i in np.arange(100):\n",
    "    sim_stat = calculate_test_statistic()\n",
    "    simulated_stats = np.append(simulated_stats, sim_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(simulated_stats>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Simulated Differences', simulated_stats).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the p-value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(simulated_difference>=observed_difference)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You work as a family physician and you want to test the following hypotheses:\n",
    "\n",
    "Null Hypothesis: Family physicians see an equal number of children and adults.\n",
    "\n",
    "Alternative Hypothesis: Family physicians see an unequal number of children and adults.\n",
    "\n",
    "You collect data and you find that in 6354 patients, 3115 were children and 3239 were adults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which test statistic(s) could be used for this hypothesis test? Which values of the test statistic point towards the alternative?\n",
    "\n",
    "A. proportion of children seen   \n",
    "B. number of children seen  \n",
    "C. number of children minus number of adults seen  \n",
    "D. absolute value of number of children minus number of adults seen  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we used a different alternative hypothesis? Which test statistics would work then? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you generate one value of the test statistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_proportions(6354, make_array(0.5, 0.5)).item(0)*6354"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you do it without using sample_proportions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Table().with_column('Patient', make_array('C', 'A')).sample(6354, with_replacement=True).column('Patient')\n",
    "np.count_nonzero(results=='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this an example of bootstrapping?  \n",
    "A. Yes, because we are sampling with replacment.  \n",
    "B. No, this is not bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats = make_array()\n",
    "\n",
    "for i in np.arange(10000):\n",
    "    stat = sample_proportions(6354, make_array(0.5, 0.5)).item(0)*6354\n",
    "    test_stats = np.append(test_stats, stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Number of Children', test_stats).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed data: You collect data and you find that in 6354 patients, 3115 were children and 3239 were adults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. reject the null  \n",
    "B. fail to reject the null  \n",
    "C. not sure  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(kids_array<=3115)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem\n",
    "\n",
    "> The distribution of sums (and averages) of large random samples (w/ replacement) are roughly normal, regardless of the distribution of the population from which the sample was drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bakeries = restaurants.where('business_name', are.containing('Bake')).where('inspection_score', are.above(-1))\n",
    "bakeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bakeries.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakeries.sample(200).column('inspection_score').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means = make_array()\n",
    "\n",
    "for i in np.arange(10000):\n",
    "    sample_mean = bakeries.sample(200).column('inspection_score').mean()\n",
    "    sample_means = np.append(sample_means, sample_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the Sample Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Table().with_column('Sample Mean', sample_means).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sample_means), np.std(sample_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample: A random 200 bakeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "one_sample = bakeries.sample(200)\n",
    "one_sample.hist('inspection_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(one_sample.column('inspection_score')), np.std(one_sample.column('inspection_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population: All bakeries in San Francisco with an inspection score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bakeries.hist('inspection_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(bakeries.column('inspection_score')), np.std(bakeries.column('inspection_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Central Limit Theorem, the SD of the distribution of the sample mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(bakeries.column('inspection_score'))/np.sqrt(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(sample_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my one sample of 200 bakeries, how can we estimate the median inspection score of all bakeries in San Francisco with an inspection score? What technique should we use?\n",
    "\n",
    "A. A/B testing  \n",
    "B. Standard hypothesis testing  \n",
    "C. Bootstrapping  \n",
    "D. Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(one_sample.column(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(bakeries.sample(bakeries.num_rows, with_replacement=True).column(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_medians = make_array()\n",
    "\n",
    "for i in np.arange(5000):\n",
    "    boot_medians = np.append(boot_medians, np.median(bakeries.sample(bakeries.num_rows, with_replacement=True).column(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Bootstrapped Medians', boot_medians).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile(2.5, boot_medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile(97.5, boot_medians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following interpretations of this confidence interval is valid?  \n",
    "A=True, B=False\n",
    "\n",
    "1. 95% of SF bakeries have an inspection score between 83 and 86.  \n",
    "2. 95% of the resamples have a median inspection score between 83 and 86.  \n",
    "3. There is a 95% chance that our sample has a median inspection score between 83 and 86.  \n",
    "4. There is a 95% chance that the median inspecition score of all SF bakeries is between 83 and 86.  \n",
    "5.  If we had taken 100 samples from the same population, about 95 of these samples would have a median inspection score between 83 and 86.  \n",
    "6.  If we had taken 100 samples from the same population, about 95 of the confidence intervals created would contain the median inspection score of all SF bakeries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability Distribution vs. Empirical Distribution of a Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_flips=100\n",
    "np.random.choice(make_array('H', 'T'), num_flips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips = Table().with_column('outcome', np.random.choice(make_array('H', 'T'), num_flips))\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistic: proportion of heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips.group('outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bakeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned = bakeries.bin('inspection_score', bins=make_array(0, 50, 60, 80, 90, 95, 100))\n",
    "binned                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you draw the histogram based on this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned = binned.with_column('percent', binned.column(1)/binned.column(1).sum()*100)\n",
    "binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakeries.hist('inspection_score', bins=make_array(0, 50, 60, 80, 90, 95, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = Table.read_table('hybrid.csv')\n",
    "hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hybrid.scatter('acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would Galton's method predict for the MSRP of a car with acceleration of 20 units?  \n",
    "A. 55,000  \n",
    "B. 65,000  \n",
    "C. 80,000  \n",
    "D. 100,000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
